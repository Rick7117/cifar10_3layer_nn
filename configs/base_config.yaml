hidden_size: 512
learning_rate: 0.001
reg_lambda: 0.0001
num_epochs: 100
batch_size: 128
activation: 'relu'
lr_decay_every: 10
lr_decay_factor: 0.9
print_every: 1