activation_func: relu
batch_size: 64
hidden_size: 512
lr: 0.001
reg_lambda: 0.01
