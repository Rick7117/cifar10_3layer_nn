activation_func: relu
batch_size: 32
hidden_size: 64
lr: 0.01
reg_lambda: 0.01
